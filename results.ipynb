{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "948c9007-e7e8-46c1-8a41-fde98544c8ea",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6692b0c-2440-4d0d-bdfb-5e645113d7df",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "def get_choice(answer_str):\n",
    "    choices = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'A)', 'B)', 'C)', 'D)', 'E)', 'F)', 'G)', 'H)', \n",
    "               'A.', 'B.', 'C.', 'D.', 'E.', 'F.', 'G.', 'H.']\n",
    "    \n",
    "    if answer_str is None:\n",
    "        return ''\n",
    "    answer_str=answer_str.strip()\n",
    "    \n",
    "    for c in choices:\n",
    "        if answer_str.startswith(c):\n",
    "            return c.replace(')', '')\n",
    "\n",
    "    if answer_str.startswith(':'):\n",
    "       return answer_str.replace(':', '').replace('.', '').strip()\n",
    "    return ''\n",
    "\n",
    "def evaluate_QA(QA_results):\n",
    "    total_em = 0.0\n",
    "    not_in_options = 0.0\n",
    "    count = 0\n",
    "    for sample in QA_results:\n",
    "        gold_answer = sample['answer'].replace('(', '').replace(')', '').strip()\n",
    "        answer_str = sample['predicted_answer'].strip() if sample['predicted_answer'] is not None else ''\n",
    "        prediction = get_choice(answer_str)\n",
    "\n",
    "        indicators = ['the correct option is', 'the correct answer is', \n",
    "                      'The correct answer is', 'The correct option is',\n",
    "                      'Thus, the answer is']\n",
    "        if prediction is None:\n",
    "            for indicator in indicators:\n",
    "                if answer_str.find(indicator)>=0:\n",
    "                    answer_str = answer_str.split(indicator)[1].strip()\n",
    "                    prediction = get_choice(answer_str)\n",
    "                    break\n",
    "\n",
    "        if prediction is None:\n",
    "            not_in_options+=1\n",
    "            \n",
    "        em_score = 1.0 if prediction == gold_answer else 0.0\n",
    "        total_em += em_score\n",
    "        count += 1\n",
    "    \n",
    "    if count!=0:\n",
    "        avg_em = total_em / count\n",
    "    else:\n",
    "        avg_em = 0\n",
    "    return avg_em\n",
    "\n",
    "def full_evaluation(result_file):\n",
    "    with open(result_file, 'r') as f:\n",
    "        all_samples = json.load(f)\n",
    "\n",
    "    executable_samples = [sample for sample in all_samples if sample['flag'] == 'success']\n",
    "    return evaluate_QA(all_samples), len(executable_samples)/len(all_samples), evaluate_QA(executable_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e09b036-3520-4931-9216-d614fcc5fdcc",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_main = pd.DataFrame(columns=[\"model\",\"iteration\",\"split\",\"iteration\",\"exec_rate\",\"exec_accuracy\",\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7775089-eca2-43d2-af6c-5ecac5dc0ee7",
   "metadata": {},
   "source": [
    "# Direct and CoT results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e238132-2200-4ab9-bf5e-690b62e05d2e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_all=[]\n",
    "for file in os.listdir(\"./outputs/results\"):\n",
    "    if \"mini_test\" in file:\n",
    "        continue\n",
    "\n",
    "    if \"Bloke\" in file:\n",
    "        continue\n",
    "\n",
    "    if \"checkpoint\" in file:\n",
    "        continue\n",
    "    \n",
    "    mode, dataset, split, model = file.split(\"_\")\n",
    "    model = model[:-5]\n",
    "    result_file = os.path.join(\"./outputs/results\",file)\n",
    "    with open(result_file, 'r') as f:\n",
    "        all_samples = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "    df=pd.DataFrame(all_samples)\n",
    "    df[\"clean_answer\"] = df.predicted_answer.apply(get_choice)\n",
    "    df = df.drop(columns=[\"question\",\"predicted_reasoning\", \"predicted_answer\"])\n",
    "    df[\"answer\"] = df.answer.str.replace('(', '').replace(')', '')\n",
    "    df[\"is_correct\"] = df.answer == df.clean_answer\n",
    "    df[\"is_empty\"] = df.clean_answer == ''\n",
    "    df[\"mode\"] = mode\n",
    "    df[\"dataset\"] = dataset\n",
    "    df[\"split\"] = split\n",
    "    df[\"model\"] = model\n",
    "    df[\"refiment\"] = 0\n",
    "    df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72eee6ee-43fc-4839-921b-845f3d3e511a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_all2=pd.concat(df_all)\n",
    "df_all3=df_all2.groupby([\"model\",\"dataset\",\"mode\"])[[\"is_correct\",\"is_empty\"]].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0019979d-6c55-4438-83b5-7319e313c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=df_all3,x=\"model\",y=\"is_correct\",col=\"dataset\",hue=\"mode\").tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "310e1829-4a29-4b2a-a889-36deb19c89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=df_all3,x=\"model\",y=\"is_empty\",col=\"dataset\",hue=\"mode\").tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0bb19bc8-58c2-4ab4-9456-418668feb670",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_all4=df_all2.loc[df_all2.is_empty!=True,:].groupby([\"model\",\"dataset\",\"mode\"])[[\"is_correct\",\"is_empty\"]].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "599f5c89-cda1-4ffa-9d12-e3e7b406b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=df_all4,x=\"model\",y=\"is_correct\",col=\"dataset\",hue=\"mode\").tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50c2ab96-7cb1-4a76-a625-9ba5cc9c0dae",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR-LSAT_dev_meta-llama-Llama-2-70b-hf-AR-LSAT-sft-lora-r-32-zero-0-neftune-5-best-zero-0_backup-random.json\n",
      "ProntoQA_dev_meta-llama-Llama-2-70b-hf-ProntoQA-sft-lora-r-32-zero-0-neftune-5-best-zero-0_backup-random.json\n",
      "ProofWriter_dev_meta-llama-Llama-2-70b-hf-ProofWriter-sft-full-0-lora-r-16-zero-0-neftune-0-best-beam5-group1-zero-0_backup-random.json\n",
      "FOLIO_dev_meta-llama-Llama-2-70b-hf-FOLIO-sft-lora-r-32-zero-0-neftune-5-best-zero-0_backup-random.json\n"
     ]
    }
   ],
   "source": [
    "df_logic=[]\n",
    "for file in os.listdir(\"./outputs/logic_inference\"):\n",
    "    if \"mini_test\" in file:\n",
    "        continue\n",
    "\n",
    "    if \"minitest\" in file:\n",
    "        continue\n",
    "\n",
    "    if \"Bloke\" in file:\n",
    "        continue\n",
    "\n",
    "    # if \"backup-random\" in file:\n",
    "    #     continue\n",
    "\n",
    "    if \"checkpoint\" in file:\n",
    "        continue\n",
    "\n",
    "    if 'self-refine' in file:\n",
    "        refine, dataset, split, model, backup = file.split(\"_\")\n",
    "        refine = int(refine.split('-')[-1])\n",
    "    else:\n",
    "        dataset, split, model, backup = file.split(\"_\")\n",
    "        refine = 0\n",
    "    \n",
    "    result_file = os.path.join(\"./outputs/logic_inference\",file)\n",
    "    with open(result_file, 'r') as f:\n",
    "        all_samples = json.load(f)\n",
    "        f.close()\n",
    "    df=pd.DataFrame(all_samples)\n",
    "    if len(df) == 0:\n",
    "        print(file)\n",
    "        continue\n",
    "    df[\"clean_answer\"] = df.predicted_answer.apply(get_choice)\n",
    "    df = df.drop(columns=[\"question\", \"predicted_answer\",\"context\"])\n",
    "    df[\"answer\"] = df.answer.str.replace('(', '').replace(')', '')\n",
    "    df[\"is_correct_backup\"] = df.answer == df.clean_answer\n",
    "    df[\"is_empty\"] = df.clean_answer == ''\n",
    "    df[\"is_correct\"] = (df[\"is_correct_backup\"]) & (df[\"flag\"] == \"success\")\n",
    "    df[\"mode\"] = 'Logic'\n",
    "    df[\"dataset\"] = dataset\n",
    "    df[\"split\"] = split\n",
    "    df[\"model\"] = model\n",
    "    df[\"refiment\"] = refine\n",
    "    df_logic.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1784d1a9-d18b-4100-a3e8-7d22317f5f38",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_programs=[]\n",
    "for file in os.listdir(\"./outputs/logic_programs\"):\n",
    "    if \"mini_test\" in file:\n",
    "        continue\n",
    "\n",
    "    if \"minitest\" in file:\n",
    "        continue\n",
    "\n",
    "    if \"Bloke\" in file:\n",
    "        continue\n",
    "\n",
    "    # if \"backup-random\" in file:\n",
    "    #     continue\n",
    "\n",
    "    if \"checkpoint\" in file:\n",
    "        continue\n",
    "\n",
    "    if 'self-refine' in file:\n",
    "        refine, dataset, split, model = file.split(\"_\")\n",
    "        refine = int(refine.split('-')[-1])\n",
    "    else:\n",
    "        dataset, split, model = file.split(\"_\")\n",
    "        refine = 0\n",
    "    \n",
    "    result_file = os.path.join(\"./outputs/logic_programs\",file)\n",
    "    with open(result_file, 'r') as f:\n",
    "        all_samples = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "    df=pd.DataFrame(all_samples)\n",
    "    if len(df) == 0:\n",
    "        print(file)\n",
    "        continue\n",
    "    df[\"dataset\"] = dataset\n",
    "    df[\"split\"] = split\n",
    "    df[\"model\"] = model[:-5]\n",
    "    df[\"refiment\"] = refine\n",
    "    df_programs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fbd9ac9-62fb-405e-a9df-fe0ada111059",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_logic2=pd.concat(df_logic)\n",
    "\n",
    "df_logic2[\"n_beam\"]=df_logic2.groupby([\"id\",\"model\",\"dataset\",\"split\",\"refiment\"]).cumcount()\n",
    "\n",
    "df_logic2 = df_logic2.loc[df_logic2[\"n_beam\"] == 0]\n",
    "\n",
    "df_total2 = pd.concat([df_all2,df_logic2])\n",
    "\n",
    "df_total5 = df_total2.loc[(df_total2[\"mode\"] == \"Logic\"),:]\n",
    "\n",
    "df_total5[\"compiled\"]=(df_total5[\"flag\"] == \"success\")\n",
    "df_total5[\"size\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c1d63f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = df_total5.groupby([\"model\",\"dataset\",\"mode\",\"split\",\"refiment\"])[[\"is_correct\",\"is_empty\",\"compiled\",\"size\"]].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88e9ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary[\"is_correct_perc\"]=100*results_summary[\"is_correct\"]/results_summary[\"size\"]\n",
    "results_summary[\"is_empty_perc\"]=100*results_summary[\"is_empty\"]/results_summary[\"size\"]\n",
    "results_summary[\"compiled_perc\"]=100*results_summary[\"compiled\"]/results_summary[\"size\"]\n",
    "results_summary[\"is_correct_compiled_perc\"]=100*results_summary[\"is_correct\"]/results_summary[\"compiled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f890d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_base_model(model_name):\n",
    "    datasets = ['AR-LSAT', 'ProntoQA', 'ProofWriter', 'FOLIO', 'LogicalDeduction']\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        if dataset in model_name:\n",
    "            return model_name.split(dataset)[0].strip('-')\n",
    "    \n",
    "    return model_name  # Return original if no match found\n",
    "\n",
    "# Apply the function to create a new column\n",
    "results_summary['base_model'] = results_summary['model'].apply(extract_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd0ad0dc-9452-4078-b678-c42edcf1b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          model_name  full  lora_r  zero  \\\n",
      "0  meta-llama-Llama-2-7b-hf-ProofWriter-sft-full-...     0      16     1   \n",
      "1  meta-llama-Llama-2-7b-hf-ProofWriter-sft-full-...     1       8     2   \n",
      "2  meta-llama-Llama-2-7b-hf-ProofWriter-sft-full-...     0      32     0   \n",
      "\n",
      "   neftune  beam  group  last_zero  \n",
      "0        0     5      1          0  \n",
      "1        1     3      2          1  \n",
      "2        0     7      3          2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_model_info(model_name):\n",
    "    info = {}\n",
    "    \n",
    "    # Extract full value\n",
    "    full_match = re.search(r'full-(\\d+)', model_name)\n",
    "    info['full'] = int(full_match.group(1)) if full_match else None\n",
    "    \n",
    "    # Extract lora-r value\n",
    "    lora_r_match = re.search(r'lora-r-(\\d+)', model_name)\n",
    "    info['lora_r'] = int(lora_r_match.group(1)) if lora_r_match else None\n",
    "    \n",
    "    # Extract zero value\n",
    "    zero_match = re.search(r'zero-(\\d+)', model_name)\n",
    "    info['zero'] = int(zero_match.group(1)) if zero_match else None\n",
    "    \n",
    "    # Extract neftune value\n",
    "    neftune_match = re.search(r'neftune-(\\d+)', model_name)\n",
    "    info['neftune'] = int(neftune_match.group(1)) if neftune_match else 0\n",
    "    \n",
    "    # Extract beam value\n",
    "    beam_match = re.search(r'beam(\\d+)', model_name)\n",
    "    info['beam'] = int(beam_match.group(1)) if beam_match else 1\n",
    "    \n",
    "    # Extract group value\n",
    "    group_match = re.search(r'group(\\d+)', model_name)\n",
    "    info['group'] = int(group_match.group(1)) if group_match else 0\n",
    "    \n",
    "    # Extract last zero value\n",
    "    last_zero_match = re.search(r'zero-(\\d+)$', model_name)\n",
    "    info['last_zero'] = int(last_zero_match.group(1)) if last_zero_match else None\n",
    "    \n",
    "    return pd.Series(info)\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'model_name': [\n",
    "        'meta-llama-Llama-2-7b-hf-ProofWriter-sft-full-0-lora-r-16-zero-1-neftune-0-best-beam5-group1-zero-0',\n",
    "        'meta-llama-Llama-2-7b-hf-ProofWriter-sft-full-1-lora-r-8-zero-2-neftune-1-best-beam3-group2-zero-1',\n",
    "        'meta-llama-Llama-2-7b-hf-ProofWriter-sft-full-0-lora-r-32-zero-0-neftune-0-best-beam7-group3-zero-2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the function to the 'model_name' column and create new columns\n",
    "df = pd.concat([df, df['model_name'].apply(extract_model_info)], axis=1)\n",
    "\n",
    "# Display the result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f277389-4c44-4d10-9f82-81c3cbc0a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = pd.concat([results_summary, results_summary['model'].apply(extract_model_info)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76813075-7695-4e5c-b29a-a16188aa15f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mode</th>\n",
       "      <th>split</th>\n",
       "      <th>refiment</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>is_empty</th>\n",
       "      <th>compiled</th>\n",
       "      <th>size</th>\n",
       "      <th>is_correct_perc</th>\n",
       "      <th>...</th>\n",
       "      <th>compiled_perc</th>\n",
       "      <th>is_correct_compiled_perc</th>\n",
       "      <th>base_model</th>\n",
       "      <th>full</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>zero</th>\n",
       "      <th>neftune</th>\n",
       "      <th>beam</th>\n",
       "      <th>group</th>\n",
       "      <th>last_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceTB-SmolLM-135M</td>\n",
       "      <td>AR-LSAT</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HuggingFaceTB-SmolLM-135M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>AR-LSAT</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>231</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>...</td>\n",
       "      <td>19.047619</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>FOLIO</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>204</td>\n",
       "      <td>39.215686</td>\n",
       "      <td>...</td>\n",
       "      <td>61.274510</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>LogicalDeduction</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>59</td>\n",
       "      <td>293</td>\n",
       "      <td>300</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>97.666667</td>\n",
       "      <td>66.211604</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>ProntoQA</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>455</td>\n",
       "      <td>500</td>\n",
       "      <td>54.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>59.780220</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1-AR-LSAT-sft-lora-r...</td>\n",
       "      <td>AR-LSAT</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>231</td>\n",
       "      <td>3.896104</td>\n",
       "      <td>...</td>\n",
       "      <td>12.987013</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1-FOLIO-sft-lora-r-3...</td>\n",
       "      <td>FOLIO</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>204</td>\n",
       "      <td>47.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>78.431373</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1-LogicalDeduction-s...</td>\n",
       "      <td>LogicalDeduction</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>32</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1-ProntoQA-sft-lora-...</td>\n",
       "      <td>ProntoQA</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "      <td>500</td>\n",
       "      <td>99.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>99.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1-ProofWriter-sft-lo...</td>\n",
       "      <td>ProofWriter</td>\n",
       "      <td>Logic</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>600</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>93.298969</td>\n",
       "      <td>mistralai-Mixtral-8x7B-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model           dataset  \\\n",
       "0                            HuggingFaceTB-SmolLM-135M           AR-LSAT   \n",
       "1                                        gpt-3.5-turbo           AR-LSAT   \n",
       "2                                        gpt-3.5-turbo             FOLIO   \n",
       "3                                        gpt-3.5-turbo  LogicalDeduction   \n",
       "4                                        gpt-3.5-turbo          ProntoQA   \n",
       "..                                                 ...               ...   \n",
       "330  mistralai-Mixtral-8x7B-v0.1-AR-LSAT-sft-lora-r...           AR-LSAT   \n",
       "331  mistralai-Mixtral-8x7B-v0.1-FOLIO-sft-lora-r-3...             FOLIO   \n",
       "332  mistralai-Mixtral-8x7B-v0.1-LogicalDeduction-s...  LogicalDeduction   \n",
       "333  mistralai-Mixtral-8x7B-v0.1-ProntoQA-sft-lora-...          ProntoQA   \n",
       "334  mistralai-Mixtral-8x7B-v0.1-ProofWriter-sft-lo...       ProofWriter   \n",
       "\n",
       "      mode split  refiment  is_correct  is_empty  compiled  size  \\\n",
       "0    Logic   dev         0           0         0         0    40   \n",
       "1    Logic   dev         0          14         0        44   231   \n",
       "2    Logic   dev         0          80         0       125   204   \n",
       "3    Logic   dev         0         194        59       293   300   \n",
       "4    Logic   dev         0         272         0       455   500   \n",
       "..     ...   ...       ...         ...       ...       ...   ...   \n",
       "330  Logic   dev         0           9         0        30   231   \n",
       "331  Logic   dev         0          96         0       160   204   \n",
       "332  Logic   dev         0         230        32       300   300   \n",
       "333  Logic   dev         0         497         0       497   500   \n",
       "334  Logic   dev         0         543         0       582   600   \n",
       "\n",
       "     is_correct_perc  ...  compiled_perc  is_correct_compiled_perc  \\\n",
       "0           0.000000  ...       0.000000                       NaN   \n",
       "1           6.060606  ...      19.047619                 31.818182   \n",
       "2          39.215686  ...      61.274510                 64.000000   \n",
       "3          64.666667  ...      97.666667                 66.211604   \n",
       "4          54.400000  ...      91.000000                 59.780220   \n",
       "..               ...  ...            ...                       ...   \n",
       "330         3.896104  ...      12.987013                 30.000000   \n",
       "331        47.058824  ...      78.431373                 60.000000   \n",
       "332        76.666667  ...     100.000000                 76.666667   \n",
       "333        99.400000  ...      99.400000                100.000000   \n",
       "334        90.500000  ...      97.000000                 93.298969   \n",
       "\n",
       "                      base_model full  lora_r  zero  neftune  beam  group  \\\n",
       "0      HuggingFaceTB-SmolLM-135M  NaN     NaN   NaN      0.0   1.0    0.0   \n",
       "1                  gpt-3.5-turbo  NaN     NaN   NaN      0.0   1.0    0.0   \n",
       "2                  gpt-3.5-turbo  NaN     NaN   NaN      0.0   1.0    0.0   \n",
       "3                  gpt-3.5-turbo  NaN     NaN   NaN      0.0   1.0    0.0   \n",
       "4                  gpt-3.5-turbo  NaN     NaN   NaN      0.0   1.0    0.0   \n",
       "..                           ...  ...     ...   ...      ...   ...    ...   \n",
       "330  mistralai-Mixtral-8x7B-v0.1  NaN    32.0   0.0      5.0   1.0    0.0   \n",
       "331  mistralai-Mixtral-8x7B-v0.1  NaN    32.0   0.0      5.0   1.0    0.0   \n",
       "332  mistralai-Mixtral-8x7B-v0.1  NaN    32.0   0.0      5.0   1.0    0.0   \n",
       "333  mistralai-Mixtral-8x7B-v0.1  NaN    32.0   0.0      5.0   1.0    0.0   \n",
       "334  mistralai-Mixtral-8x7B-v0.1  NaN    32.0   0.0      5.0   1.0    0.0   \n",
       "\n",
       "     last_zero  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "..         ...  \n",
       "330        0.0  \n",
       "331        0.0  \n",
       "332        0.0  \n",
       "333        0.0  \n",
       "334        0.0  \n",
       "\n",
       "[335 rows x 21 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "54cb8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary['is_tuned'] = results_summary['model'].str.contains('sft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aaf90387",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary[\"is_correct_compiled_perc\"] = results_summary.is_correct_compiled_perc.fillna(0)\n",
    "results_summary[\"mode\"] = results_summary[\"mode\"].fillna(\"Logic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "11049dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=results_summary.loc[(results_filtered.last_zero==0) & (results_summary.dataset==\"ProofWriter\") & (results_summary.split==\"dev\") & (results_summary.is_tuned==True)],x=\"compiled_perc\",y=\"is_correct_perc\",col=\"beam\",row=\"lora_r\").tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "86ece151",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filtered = results_summary.loc[(results_summary.full.isna()) & (results_summary.group==0) & (results_summary.beam==1) & (results_summary.base_model=='meta-llama-Llama-2-7b-hf') & (results_summary.split==\"dev\") & (results_summary.is_tuned==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0c2cd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_filtered_old=pd.read_csv('results_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71f15579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "friedman_df = results_filtered.pivot(\n",
    "    index='dataset',  # Rows will be datasets\n",
    "    columns=['lora_r', 'zero', 'neftune', 'last_zero'],  # Combine hyperparameters for columns\n",
    "    values='is_correct_perc'  # The values will be accuracies\n",
    ")\n",
    "\n",
    "# If you need to reset the index\n",
    "# friedman_df = friedman_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43ed75fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>lora_r</th>\n",
       "      <th colspan=\"8\" halign=\"left\">16.0</th>\n",
       "      <th colspan=\"5\" halign=\"left\">32.0</th>\n",
       "      <th colspan=\"8\" halign=\"left\">8.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <th colspan=\"4\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"4\" halign=\"left\">1.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1.0</th>\n",
       "      <th colspan=\"4\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"4\" halign=\"left\">1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neftune</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_zero</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR-LSAT</th>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.597403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOLIO</th>\n",
       "      <td>31.372549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.274510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.313725</td>\n",
       "      <td>13.235294</td>\n",
       "      <td>32.352941</td>\n",
       "      <td>13.725490</td>\n",
       "      <td>38.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>12.254902</td>\n",
       "      <td>31.862745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.352941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.470588</td>\n",
       "      <td>13.235294</td>\n",
       "      <td>25.980392</td>\n",
       "      <td>12.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogicalDeduction</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProntoQA</th>\n",
       "      <td>98.400000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>94.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>92.800000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.800000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>96.800000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>81.800000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>74.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProofWriter</th>\n",
       "      <td>85.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>56.833333</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>84.666667</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>84.833333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>57.166667</td>\n",
       "      <td>35.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lora_r                 16.0                                             \\\n",
       "zero                    0.0                                        1.0   \n",
       "neftune                 0.0                   5.0                  0.0   \n",
       "last_zero               0.0        1.0        0.0       1.0        0.0   \n",
       "dataset                                                                  \n",
       "AR-LSAT            0.432900   0.000000   0.432900  0.000000   0.865801   \n",
       "FOLIO             31.372549   0.000000  36.274510  0.000000  34.313725   \n",
       "LogicalDeduction  62.000000   4.666667  59.666667  4.666667  58.333333   \n",
       "ProntoQA          98.400000  14.800000  94.800000  0.400000  39.800000   \n",
       "ProofWriter       85.500000   1.333333  85.500000  2.833333  59.500000   \n",
       "\n",
       "lora_r                                                  32.0             ...  \\\n",
       "zero                                                     0.0             ...   \n",
       "neftune                            5.0                   0.0             ...   \n",
       "last_zero               1.0        0.0        1.0        0.0        1.0  ...   \n",
       "dataset                                                                  ...   \n",
       "AR-LSAT            0.000000   0.865801   0.000000   2.597403   0.000000  ...   \n",
       "FOLIO             13.235294  32.352941  13.725490  38.235294   0.000000  ...   \n",
       "LogicalDeduction  65.000000  62.000000  64.333333  53.666667   7.666667  ...   \n",
       "ProntoQA          91.200000  35.000000  92.800000  99.000000  15.600000  ...   \n",
       "ProofWriter       15.000000  56.833333   4.166667  84.666667  11.000000  ...   \n",
       "\n",
       "lora_r                                       8.0                        \\\n",
       "zero                    1.0                   0.0                        \n",
       "neftune                 5.0                   0.0                  5.0   \n",
       "last_zero               0.0        1.0        0.0       1.0        0.0   \n",
       "dataset                                                                  \n",
       "AR-LSAT            1.298701   0.000000   0.000000  0.000000   0.432900   \n",
       "FOLIO             35.294118  12.254902  31.862745  0.000000  32.352941   \n",
       "LogicalDeduction  65.333333  69.333333  53.666667  1.000000  52.666667   \n",
       "ProntoQA          55.800000  97.000000  96.800000  6.200000  95.400000   \n",
       "ProofWriter       63.500000   6.666667  84.833333  3.166667  84.000000   \n",
       "\n",
       "lora_r                                                                   \n",
       "zero                               1.0                                   \n",
       "neftune                            0.0                   5.0             \n",
       "last_zero               1.0        0.0        1.0        0.0        1.0  \n",
       "dataset                                                                  \n",
       "AR-LSAT            0.000000   1.298701   0.000000   1.298701   0.000000  \n",
       "FOLIO              0.000000  26.470588  13.235294  25.980392  12.745098  \n",
       "LogicalDeduction   1.000000  50.333333  56.333333  54.333333  55.000000  \n",
       "ProntoQA          19.600000  32.400000  81.800000  31.800000  74.600000  \n",
       "ProofWriter        2.833333  59.166667  44.000000  57.166667  35.666667  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friedman_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f5018420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test statistic: 72.87694113398338, p-value: 4.338420281127744e-07\n",
      "Significant differences found. Performing Nemenyi post-hoc test...\n",
      "Best hyperparameter set is Set 11 with average rank 4.3\n",
      "P-values comparing the best set to others:\n",
      "0     1.000000\n",
      "1     0.033243\n",
      "2     1.000000\n",
      "3     0.028368\n",
      "4     0.999980\n",
      "5     0.979725\n",
      "6     0.999864\n",
      "7     0.960435\n",
      "8     1.000000\n",
      "9     0.136224\n",
      "10    1.000000\n",
      "11    0.092402\n",
      "12    1.000000\n",
      "13    0.913888\n",
      "14    1.000000\n",
      "15    0.996884\n",
      "16    0.999864\n",
      "17    0.030720\n",
      "18    0.999990\n",
      "19    0.045233\n",
      "20    0.989007\n",
      "21    0.913888\n",
      "22    0.992131\n",
      "23    0.813728\n",
      "Name: 10, dtype: float64\n",
      "Sets not significantly different from the best set: Index([0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume 'data' is a numpy array of shape (datasets, hyperparameter_sets)\n",
    "data = np.array(\n",
    "    friedman_df\n",
    ")\n",
    "\n",
    "# Perform Friedman test\n",
    "from scipy.stats import friedmanchisquare\n",
    "stat, p = friedmanchisquare(*[data[:, i] for i in range(data.shape[1])])\n",
    "print(f'Friedman test statistic: {stat}, p-value: {p}')\n",
    "\n",
    "# If significant, proceed with Nemenyi test\n",
    "if p < 0.05:\n",
    "    print('Significant differences found. Performing Nemenyi post-hoc test...')\n",
    "    p_values = sp.posthoc_nemenyi_friedman(data)\n",
    "\n",
    "    # Calculate average ranks\n",
    "    from scipy.stats import rankdata\n",
    "    ranks = [rankdata(-row) for row in data]\n",
    "    avg_ranks = np.mean(ranks, axis=0)\n",
    "\n",
    "    # Identify the best hyperparameter set(s)\n",
    "    best_index = np.argmin(avg_ranks)\n",
    "    print(f'Best hyperparameter set is Set {best_index+1} with average rank {avg_ranks[best_index]}')\n",
    "\n",
    "    # Examine p-values for the best set\n",
    "    best_set_p_values = p_values.iloc[best_index]\n",
    "    print(f'P-values comparing the best set to others:\\n{best_set_p_values}')\n",
    "\n",
    "    # Identify sets not significantly different from the best set\n",
    "    not_significant = best_set_p_values[best_set_p_values >= 0.05].index\n",
    "    print(f'Sets not significantly different from the best set: {not_significant}')\n",
    "else:\n",
    "    print('No significant differences found among hyperparameter sets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a11d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf0b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1f828-db3b-482c-b537-0fadbfa043e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a82ac77c",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# Extraction function\n",
    "def tflog2pandas(path):\n",
    "    runlog_data = pd.DataFrame({\"metric\": [], \"value\": [], \"step\": []})\n",
    "    try:\n",
    "        event_acc = EventAccumulator(path)\n",
    "        event_acc.Reload()\n",
    "        tags = event_acc.Tags()[\"scalars\"]\n",
    "        for tag in tags:\n",
    "            event_list = event_acc.Scalars(tag)\n",
    "            values = list(map(lambda x: x.value, event_list))\n",
    "            step = list(map(lambda x: x.step, event_list))\n",
    "            r = {\"metric\": [tag] * len(step), \"value\": values, \"step\": step}\n",
    "            r = pd.DataFrame(r)\n",
    "            runlog_data = pd.concat([runlog_data, r])\n",
    "    # Dirty catch of DataLossError\n",
    "    except Exception:\n",
    "        print(\"Event file possibly corrupt: {}\".format(path))\n",
    "        traceback.print_exc()\n",
    "    return runlog_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0c1091b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "path=\"/mnt/evafs/groups/luckner-lab/models/mistralai/Mistral-7B-v0.1/LogicalDeduction/sft/runs/Jun11_22-53-05_dgx-4.eden\" #folderpath\n",
    "df=tflog2pandas(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87886d6a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train/loss', 'train/grad_norm', 'train/learning_rate',\n",
       "       'train/epoch', 'eval/loss', 'eval/runtime',\n",
       "       'eval/samples_per_second', 'eval/steps_per_second',\n",
       "       'train/train_runtime', 'train/train_samples_per_second',\n",
       "       'train/train_steps_per_second', 'train/total_flos',\n",
       "       'train/train_loss'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52377fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/loss</td>\n",
       "      <td>3.482000e-01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/loss</td>\n",
       "      <td>9.910000e-02</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/loss</td>\n",
       "      <td>5.540000e-02</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/loss</td>\n",
       "      <td>4.700000e-02</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/loss</td>\n",
       "      <td>4.270000e-02</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/train_runtime</td>\n",
       "      <td>7.297424e+02</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/train_samples_per_second</td>\n",
       "      <td>2.168000e+00</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/train_steps_per_second</td>\n",
       "      <td>5.430000e-01</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/total_flos</td>\n",
       "      <td>1.106620e+17</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/train_loss</td>\n",
       "      <td>4.197049e-02</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            metric         value   step\n",
       "0                       train/loss  3.482000e-01   10.0\n",
       "1                       train/loss  9.910000e-02   20.0\n",
       "2                       train/loss  5.540000e-02   30.0\n",
       "3                       train/loss  4.700000e-02   40.0\n",
       "4                       train/loss  4.270000e-02   50.0\n",
       "..                             ...           ...    ...\n",
       "0              train/train_runtime  7.297424e+02  396.0\n",
       "0   train/train_samples_per_second  2.168000e+00  396.0\n",
       "0     train/train_steps_per_second  5.430000e-01  396.0\n",
       "0                 train/total_flos  1.106620e+17  396.0\n",
       "0                 train/train_loss  4.197049e-02  396.0\n",
       "\n",
       "[167 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3e0f5ab-9411-4fad-8b35-a1e1fc47c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(data=df.loc[df.metric==\"eval/loss\",:],x=\"step\",y=\"value\").set(ylabel=\"Train Loss\", title=\"LogicalDeduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef674567",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Train Loss'), Text(0.5, 1.0, 'LogicalDeduction')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=df.loc[df.metric==\"train/loss\",:],x=\"step\",y=\"value\").set(ylabel=\"Train Loss\", title=\"LogicalDeduction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
